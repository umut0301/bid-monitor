#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
@Time    : 2026/01/31 17:00
@Author  : Manus AI
@File    : main_dashboard.py
@Desc    : Streamlitæ•°æ®çœ‹æ¿
"""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.core.database import SessionLocal
from app.models.bid_project import BidProject, CrawlLog
from sqlalchemy import func, desc


st.set_page_config(
    page_title="æ‹›æŠ•æ ‡ç›‘æ§ç³»ç»Ÿ",
    page_icon="ğŸ”",
    layout="wide"
)


def get_statistics():
    """è·å–ç»Ÿè®¡æ•°æ®"""
    db = SessionLocal()
    try:
        # æ€»é¡¹ç›®æ•°
        total_projects = db.query(func.count(BidProject.project_id)).scalar()

        # ä»Šæ—¥æ–°å¢
        today = datetime.now().date()
        today_projects = db.query(func.count(BidProject.project_id)).filter(
            func.date(BidProject.created_at) == today
        ).scalar()

        # é«˜åˆ†é¡¹ç›®ï¼ˆ>= 3.0ï¼‰
        high_score_projects = db.query(func.count(BidProject.project_id)).filter(
            BidProject.match_score >= 3.0
        ).scalar()

        # æœ€è¿‘ä¸€æ¬¡çˆ¬å–æ—¶é—´
        last_crawl = db.query(CrawlLog).order_by(desc(CrawlLog.start_time)).first()
        last_crawl_time = last_crawl.start_time if last_crawl else None

        return {
            'total': total_projects or 0,
            'today': today_projects or 0,
            'high_score': high_score_projects or 0,
            'last_crawl': last_crawl_time
        }
    finally:
        db.close()


def get_recent_projects(limit=20, min_score=0.0):
    """è·å–æœ€è¿‘çš„é¡¹ç›®åˆ—è¡¨"""
    db = SessionLocal()
    try:
        projects = db.query(BidProject).filter(
            BidProject.match_score >= min_score
        ).order_by(
            desc(BidProject.created_at)
        ).limit(limit).all()

        data = []
        for p in projects:
            data.append({
                'æ ‡é¢˜': p.title,
                'åŒ¹é…åˆ†æ•°': f"{p.match_score:.2f}",
                'ä¸šä¸»å•ä½': p.owner_unit or 'æœªçŸ¥',
                'é¢„ç®—(ä¸‡å…ƒ)': p.budget or 'æœªçŸ¥',
                'æŠ¥åæˆªæ­¢': p.registration_end or 'æœªçŸ¥',
                'æŠ“å–æ—¶é—´': p.created_at.strftime('%Y-%m-%d %H:%M') if p.created_at else '',
                'è¯¦æƒ…é“¾æ¥': p.source_url
            })

        return pd.DataFrame(data)
    finally:
        db.close()


def get_crawl_logs(limit=10):
    """è·å–çˆ¬å–æ—¥å¿—"""
    db = SessionLocal()
    try:
        logs = db.query(CrawlLog).order_by(desc(CrawlLog.start_time)).limit(limit).all()

        data = []
        for log in logs:
            data.append({
                'ä»»åŠ¡ID': log.task_id[:8],
                'å¼€å§‹æ—¶é—´': log.start_time.strftime('%Y-%m-%d %H:%M'),
                'ç»“æŸæ—¶é—´': log.end_time.strftime('%Y-%m-%d %H:%M') if log.end_time else '-',
                'æˆåŠŸæ•°': log.success_count,
                'å¤±è´¥æ•°': log.failed_count,
                'çŠ¶æ€': log.status
            })

        return pd.DataFrame(data)
    finally:
        db.close()


def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ” æ‹›æŠ•æ ‡ç›‘æ§ç³»ç»Ÿ")
    st.markdown("---")

    # ç»Ÿè®¡æ•°æ®
    stats = get_statistics()

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ€»é¡¹ç›®æ•°", stats['total'])

    with col2:
        st.metric("ä»Šæ—¥æ–°å¢", stats['today'])

    with col3:
        st.metric("é«˜åˆ†é¡¹ç›®", stats['high_score'])

    with col4:
        if stats['last_crawl']:
            last_crawl_str = stats['last_crawl'].strftime('%H:%M')
            st.metric("æœ€è¿‘çˆ¬å–", last_crawl_str)
        else:
            st.metric("æœ€è¿‘çˆ¬å–", "æš‚æ— ")

    st.markdown("---")

    # ä¾§è¾¹æ ç­›é€‰
    st.sidebar.header("ç­›é€‰æ¡ä»¶")
    min_score = st.sidebar.slider("æœ€ä½åŒ¹é…åˆ†æ•°", 0.0, 10.0, 0.0, 0.5)
    limit = st.sidebar.slider("æ˜¾ç¤ºæ•°é‡", 10, 100, 20, 10)

    # é¡¹ç›®åˆ—è¡¨
    st.header("ğŸ“‹ æœ€è¿‘é¡¹ç›®")
    df_projects = get_recent_projects(limit=limit, min_score=min_score)

    if not df_projects.empty:
        # ä½¿ç”¨dataframeæ˜¾ç¤ºï¼Œæ”¯æŒæ’åº
        st.dataframe(
            df_projects,
            use_container_width=True,
            hide_index=True
        )

        # è¯¦æƒ…å±•å¼€
        st.subheader("é¡¹ç›®è¯¦æƒ…")
        selected_title = st.selectbox("é€‰æ‹©é¡¹ç›®æŸ¥çœ‹è¯¦æƒ…", df_projects['æ ‡é¢˜'].tolist())

        if selected_title:
            selected_row = df_projects[df_projects['æ ‡é¢˜'] == selected_title].iloc[0]
            st.markdown(f"**æ ‡é¢˜**: {selected_row['æ ‡é¢˜']}")
            st.markdown(f"**åŒ¹é…åˆ†æ•°**: {selected_row['åŒ¹é…åˆ†æ•°']}")
            st.markdown(f"**ä¸šä¸»å•ä½**: {selected_row['ä¸šä¸»å•ä½']}")
            st.markdown(f"**é¢„ç®—**: {selected_row['é¢„ç®—(ä¸‡å…ƒ)']} ä¸‡å…ƒ")
            st.markdown(f"**æŠ¥åæˆªæ­¢**: {selected_row['æŠ¥åæˆªæ­¢']}")
            st.markdown(f"**è¯¦æƒ…é“¾æ¥**: [{selected_row['è¯¦æƒ…é“¾æ¥']}]({selected_row['è¯¦æƒ…é“¾æ¥']})")
    else:
        st.info("æš‚æ— ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")

    st.markdown("---")

    # çˆ¬å–æ—¥å¿—
    st.header("ğŸ“ çˆ¬å–æ—¥å¿—")
    df_logs = get_crawl_logs(limit=10)

    if not df_logs.empty:
        st.dataframe(
            df_logs,
            use_container_width=True,
            hide_index=True
        )
    else:
        st.info("æš‚æ— çˆ¬å–æ—¥å¿—")


if __name__ == "__main__":
    main()
